# Invetigating Adaptive Epistasis using *Dmel* RILs

This is a collaborative project involving genotyping and phenotyping of two sets of *Drosophila melanogaster* RILs. One set consists of a France *vs* Zambia (France RILs) cross and the other an Ethiopia *vs* Zambia (Ethiopia RILs) cross. For each set, two phenotypes have been measured. For the France RILs, the phenotypes were ethanol tolerance and cold tolerance. For the Ethiopia RILs, the phenotypes were wing length and pigmentation. The pigmentation phenotype is further subdivided into three distinct measures: pigmentation score in gray scale for the background of the mesopleura (a thorax trait), and two abdominal traits, a pigmentation score the 4th abdominal segment (A4 Background), and the proportion of the 4th abdominal background covered by a black stripe.

The genomes for each RIL and the parental strains were obtained with Next Gen sequencing using Illumina platform.

## DNA Alignment
*Scripts for this section are located in the _Alignment_ directory.*

This section contains the steps taken to analyse the genomic data, starting with the fastq files output from the Illumina sequecing.

We used the UW-Madison Center for High Throughput Computing (CHTC) to perform the DNA alignment of our samples. Using CHTC allowed us to greatly parallelize the alignment step. It required that our initial fastq files be split in shorter files and each of these shorter fastq files were submitted as independent jobs to be aligned - and then latter merged back together. The *fastq_processing1.sh* handles the splitting step for each sample and generates a file listing all the shorter fastq blocks which will be used for the parallel submission. After running this script locally, in the same folder with the fastq files to be split, the block files and the newly generated *Seq_list_single.txt* file need to be uploaded to CHTC.

On CHTC, after the files are placed in their appropriate directories, we submitted the jobs with the *align_pt1.sub* script. This script uses as executable file the *align_pt1.sh* script. The *align_pt1.sh* script will perform the DNA alignment using bwa mem. The complete pipeline used in each parallel job also included steps using *samtools* to process the bam files. It uses *collate* to organize the reads, *fixmate* to correct any flaws in read-pairing, *sort* to sort the reads and finally *markdup* with *-r* flag to identify and remove duplicate reads. In the end, we have bam files sorted and without duplicates for each fastq block. The block files need to be download to continue the pipeline locally.

The next step uses a simple script, *block2rmdupbam.sh* to merge the blocks and remove duplicates again if any was still left after the merging. Starting from here, the pipeline uses one script if you are handling the parental genomes and another if you analyzing the RIL genomes. They both start by using GATK to generate a bam files realigning the reads around indels. But while the parental genome script continues to generate fasta files for each *Dmel* chromosome arm (X, 2L, 2R, 3L, and 3R) the script for the RILs stops at the realigned bam files.

To generate the fasta files from the vcf files I am having to create a new pipeline, diverging again from the NEXUS pipuline. Previous, in the NEXUS, the custom made 'VCF\_to\_Seq' perl script would adjust the size of the contigs based on the indel and sites (shifted) vcf. Because my genome sizes were not shifted, since I did not use two rounds of DNA alignment, using indel and sites vcf was resulting in fasta of the wrong size. Now, alternatively, I am using a new set of custom made scripts, starting with *indel\_vcf.py*, to read the indel vcf file from GATK and create a vcf file with the location of all the indels - adding 3 extra sites around them - to be filtered out. Then, I use _bcftools filter_ to create a new vcf file called _\_exclude.vcf_ including only low quality (<32, as per criterium of the VCF\_to\_Seq perl script, also remove GT=./. - missing data) sites. Using _bcftools concat_ to concatenate the sites in indel regions and the sites "to exclude" I generate a _\_mask.vcf_ file that will include all the sites to be masked. Following that, the mask vcf file will be used along the _\_sites.vcf_ file to generate consensus sequence with _bcftool consensus_. The output fasta is then split into one fasta per chromosome arm with the script _split\_fasta.py_. At this point, the fasta files do not contain ambiguity code yet. I use the _iupac\_fasta.py_ script for each chrm arm fasta file to add the IUPAC ambiguity code to the fasta files. Lastly, they are validated with the _fasta\_validate.py_ script, which will check if the final fasta files for the following things: (1) whether they are the right size, (2) whether they were filtered out for the correct things (indels, low quality, and missing data), (3) whether the ALT allele is present in the file, and (4) whether IUPAC ambiguity codes were used correctly. The validate script is not exhaustive, it only checks a handful of randomly selected sites for each of these categories.

The RILs realign bamfiles and the fasta files will be used as input for the steps. First, the fasta files will be used to generate ancestry panel files. Then, the RIL realigned bam files and the panel files will be used to generate ancestry calls for each RIL. Let's discuss the steps to generate panel first.

## Ancestry calls
*Scripts for this section can be found in the _Ancestry_ directory.*

Panel files were obtained with the script _panel\_pipeline.sh_. This script uses the perl script _find\_snps.pl_ to generate one panel file per chromosome arm for each RIL data set. Order of the genomes matter and herein EF and FR were used first and will have genotype 0. The panel files are stored in their RIL's respective folders along the bam files for all the RILs (already without duplicates and realigned around indels). Then, we call the script _ancestry.sh_ to use the panels and bam files to call AncestryHMM and obtain posterior ancestry probabilities for each RIL. The _ancestry.sh_ script loops through each RIL and each chromosome arm to obtain ril-arm-specific mpileup files (obtained with _samtools mpileup_) and the ril-arm-specific panel files (obtained with the _populate\_snp\_matrix.pl_ script). To adjust the distance between the SNPs accordingly to the RIL experimental design we used _recomb.csv_ files generated for each RIL set and chromosome arm based on how many generations of recombination they had and on the recombination rates for _Dmel_ from Comeron et al. 2012. The distance adjustment is made with the _rec\_map.py_ script. With the panel files per RIL per arm we call _ancestry\_hmm_ to obtain the posterior probabilities.

Following this, we used the script _RIL\_genotypes\_windows.pl_, placed in the _posteriors_ folder, to call ancestries for windows and not per SNP. The files delimiting the window sizes need to be located in the _posterior_ folders as well. Here, we used _windows\_ZI1k\_Chr*.txt_, which has windows defined to contain 1k SNPs in the ZI population. We have to manually update the genotypes perl script to ensure the script has the correct RILs at the _"@ my RILS"_ variable, we also need to manually input the output file name.

We obtained the ancestry calls in the files: _*\_RIL\_genotypes\_winZI1k.txt_ and did a quick imputation to fill the gaps of at most 10 windows of missing data with the surrounding genotype if the surrounding genotypes were the same for each line. The files with imputation are called _*\_RIL\_genotypes\_winZI1k\_gap10.txt_. In total, EF had 3892 window positions with missing data (out of 6445 total, so 60.39%) before imputation, and FR had 1815 windows with missing data (28.16%). After imputation, EF had 1263 windows with missing data (19.60%) and FR had 274 (4.25%). After imputation, of the EF lines, 3 of them had more than 5% missing data (E191R with 7.65%, E107R with 6.24%, and E122R with 5.93%). The FR line with the largest amount of missing data was F401R (1.36%). - Imputation was done with the _missing\_genotypes.py_ script and missing data count was done with the _count\_ril\_missingdata.py_ script.

## G x P input files
*Scripts for this section can be found in the _GenoPheno_ directory.*

We combined the ancestry genotypes per window obtained above with phenotypic data to generate files that will be analyzed in our mapping and epistasis analyses. Currently, our focus is on using the r/qtl R package (source). We used a set of files and scripts to generate the input files, as described below.

We used _input\_rqtl\_nopheno.py_ to transform the data into the input format for rqtl, then used _input\_rqtl\_addpheno.py_ to add the desired phenotype. We used the script _missing\_genotypes.py_ to attempt to imputate some of the missing windows (if they were surrounded by the same genotype and there were no more than 10 contiguous missing windows). We used the script _window\_merge\_genotype.py_ to merge neighboring windows if the genotype for these windows were the same for all the RILs. The same script (_window\_merge\_genotype.py_) also filters out windows in which more than 10 RILs have missing data for that window. Lastly, we used the script _comeron\_rqtl.py_ to add recombination data to the file, basically adding the cM position for the midpoint of each window.

## R/qtl
*Scripts for this section can be found in the _rqtl_ directory.*
We used _window\_merge\_genotype.py_ to reduce the input file combining windows there were next to each other and had the same genotype for ALL the lines used, since the tests would be identical.
